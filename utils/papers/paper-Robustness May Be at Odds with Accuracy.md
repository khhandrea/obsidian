---
created-at: 2023-11-21T14:21
tags:
  - paper
description: Robust-accuracy trade-off
annotation-target: https://arxiv.org/pdf/1805.12152.pdf
---
# Robustness May Be at Odds with Accuracy

>%%
>```annotation-json
>{"created":"2023-11-21T13:56:56.001Z","updated":"2023-11-21T13:56:56.001Z","document":{"title":"1805.12152.pdf","link":[{"href":"urn:x-pdf:a71a9efd73eb9d5c0c5d219b18fbed03"},{"href":"https://arxiv.org/pdf/1805.12152.pdf"}],"documentFingerprint":"a71a9efd73eb9d5c0c5d219b18fbed03"},"uri":"https://arxiv.org/pdf/1805.12152.pdf","target":[{"source":"https://arxiv.org/pdf/1805.12152.pdf","selector":[{"type":"TextPositionSelector","start":364,"end":478},{"type":"TextQuoteSelector","exact":"training robust models may not only be more resource-consuming,but also lead to a reduction of standard accuracy. ","prefix":"d generalization. Specifically, ","suffix":"We demonstrate that this trade-o"}]}]}
>```
>%%
>*%%PREFIX%%d generalization. Specifically,%%HIGHLIGHT%% ==training robust models may not only be more resource-consuming,but also lead to a reduction of standard accuracy.== %%POSTFIX%%We demonstrate that this trade-o*
>%%LINK%%[[#^svpjofif6el|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^svpjofif6el


>%%
>```annotation-json
>{"created":"2023-11-21T13:57:07.166Z","updated":"2023-11-21T13:57:07.166Z","document":{"title":"1805.12152.pdf","link":[{"href":"urn:x-pdf:a71a9efd73eb9d5c0c5d219b18fbed03"},{"href":"https://arxiv.org/pdf/1805.12152.pdf"}],"documentFingerprint":"a71a9efd73eb9d5c0c5d219b18fbed03"},"uri":"https://arxiv.org/pdf/1805.12152.pdf","target":[{"source":"https://arxiv.org/pdf/1805.12152.pdf","selector":[{"type":"TextPositionSelector","start":600,"end":654},{"type":"TextQuoteSelector","exact":" provably exists in a fairly simple andnatural setting","prefix":"ess to adversarial perturbations","suffix":". These findings also corroborat"}]}]}
>```
>%%
>*%%PREFIX%%ess to adversarial perturbations%%HIGHLIGHT%% ==provably exists in a fairly simple andnatural setting== %%POSTFIX%%. These findings also corroborat*
>%%LINK%%[[#^75iug3eabu9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^75iug3eabu9


>%%
>```annotation-json
>{"created":"2023-11-21T13:57:37.855Z","updated":"2023-11-21T13:57:37.855Z","document":{"title":"1805.12152.pdf","link":[{"href":"urn:x-pdf:a71a9efd73eb9d5c0c5d219b18fbed03"},{"href":"https://arxiv.org/pdf/1805.12152.pdf"}],"documentFingerprint":"a71a9efd73eb9d5c0c5d219b18fbed03"},"uri":"https://arxiv.org/pdf/1805.12152.pdf","target":[{"source":"https://arxiv.org/pdf/1805.12152.pdf","selector":[{"type":"TextPositionSelector","start":988,"end":1108},{"type":"TextQuoteSelector","exact":"the representations learned by robust models tend to align betterwith salient data characteristics and human perception.","prefix":" result in unexpected benefits: ","suffix":"1 IntroductionDeep learning mode"}]}]}
>```
>%%
>*%%PREFIX%%result in unexpected benefits:%%HIGHLIGHT%% ==the representations learned by robust models tend to align betterwith salient data characteristics and human perception.== %%POSTFIX%%1 IntroductionDeep learning mode*
>%%LINK%%[[#^glri2qihix|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^glri2qihix


>%%
>```annotation-json
>{"created":"2023-11-21T14:30:16.846Z","updated":"2023-11-21T14:30:16.846Z","document":{"title":"1805.12152.pdf","link":[{"href":"urn:x-pdf:a71a9efd73eb9d5c0c5d219b18fbed03"},{"href":"https://arxiv.org/pdf/1805.12152.pdf"}],"documentFingerprint":"a71a9efd73eb9d5c0c5d219b18fbed03"},"uri":"https://arxiv.org/pdf/1805.12152.pdf","target":[{"source":"https://arxiv.org/pdf/1805.12152.pdf","selector":[{"type":"TextPositionSelector","start":3736,"end":3967},{"type":"TextQuoteSelector","exact":"eventhough training models to be adversarially robust can be beneficial in the regime of limited training data, ingeneral, there can be an inherent trade-off between the standard accuracy and adversarially robust accuracy of amodel","prefix":"mentally at odds. Specifically, ","suffix":". In fact, we show that this tra"}]}]}
>```
>%%
>*%%PREFIX%%mentally at odds. Specifically,%%HIGHLIGHT%% ==eventhough training models to be adversarially robust can be beneficial in the regime of limited training data, ingeneral, there can be an inherent trade-off between the standard accuracy and adversarially robust accuracy of amodel== %%POSTFIX%%. In fact, we show that this tra*
>%%LINK%%[[#^nrjc5b4qg8j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nrjc5b4qg8j


>%%
>```annotation-json
>{"created":"2023-11-21T15:14:43.932Z","updated":"2023-11-21T15:14:43.932Z","document":{"title":"1805.12152.pdf","link":[{"href":"urn:x-pdf:a71a9efd73eb9d5c0c5d219b18fbed03"},{"href":"https://arxiv.org/pdf/1805.12152.pdf"}],"documentFingerprint":"a71a9efd73eb9d5c0c5d219b18fbed03"},"uri":"https://arxiv.org/pdf/1805.12152.pdf","target":[{"source":"https://arxiv.org/pdf/1805.12152.pdf","selector":[{"type":"TextPositionSelector","start":9074,"end":9178},{"type":"TextQuoteSelector","exact":"Our point of start is a popular view of adversarialtraining as the “ultimate” form of data augmentation.","prefix":"as a Form of Data Augmentation. ","suffix":" According to this view, the adv"}]}]}
>```
>%%
>*%%PREFIX%%as a Form of Data Augmentation.%%HIGHLIGHT%% ==Our point of start is a popular view of adversarialtraining as the “ultimate” form of data augmentation.== %%POSTFIX%%According to this view, the adv*
>%%LINK%%[[#^4liwy9puzzo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4liwy9puzzo


>%%
>```annotation-json
>{"created":"2023-11-21T15:15:12.713Z","updated":"2023-11-21T15:15:12.713Z","document":{"title":"1805.12152.pdf","link":[{"href":"urn:x-pdf:a71a9efd73eb9d5c0c5d219b18fbed03"},{"href":"https://arxiv.org/pdf/1805.12152.pdf"}],"documentFingerprint":"a71a9efd73eb9d5c0c5d219b18fbed03"},"uri":"https://arxiv.org/pdf/1805.12152.pdf","target":[{"source":"https://arxiv.org/pdf/1805.12152.pdf","selector":[{"type":"TextPositionSelector","start":9367,"end":9494},{"type":"TextQuoteSelector","exact":"inding the worst-case δ corresponds to augmenting the training data in the “mostconfusing” and thus also “most helpful” manner.","prefix":"bustnessconsiderations). Thus, f","suffix":" A key implication of this view "}]}]}
>```
>%%
>*%%PREFIX%%bustnessconsiderations). Thus, f%%HIGHLIGHT%% ==inding the worst-case δ corresponds to augmenting the training data in the “mostconfusing” and thus also “most helpful” manner.== %%POSTFIX%%A key implication of this view*
>%%LINK%%[[#^zfwepkreh4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zfwepkreh4
