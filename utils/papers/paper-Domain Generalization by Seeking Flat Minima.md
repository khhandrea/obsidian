---
created-at: 2023-09-26T22:58
tags:
  - paper
description: Domain Generalization by Seeking Flat Minima
annotation-target: https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf
---
# SWAD: Domain Generalization by Seeking Flat Minima


>%%
>```annotation-json
>{"created":"2023-09-27T01:06:43.577Z","updated":"2023-09-27T01:06:43.577Z","document":{"title":"NeurIPS-2021-swad-domain-generalization-by-seeking-flat-minima-Paper.pdf","link":[{"href":"urn:x-pdf:7aedd41fa0e0b1afddabbfe8c70653a2"},{"href":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf"}],"documentFingerprint":"7aedd41fa0e0b1afddabbfe8c70653a2"},"uri":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf","target":[{"source":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf","selector":[{"type":"TextPositionSelector","start":795,"end":1000},{"type":"TextQuoteSelector","exact":"In this paper, wetheoretically show that finding flat minima results in a smaller domain generaliza-tion gap. We also propose a simple yet effective method, named Stochastic WeightAveraging Densely (SWAD),","prefix":"bility by seeking sharp minima. ","suffix":" to find flat minima. SWAD finds"}]}]}
>```
>%%
>*%%PREFIX%%bility by seeking sharp minima.%%HIGHLIGHT%% ==In this paper, wetheoretically show that finding flat minima results in a smaller domain generaliza-tion gap. We also propose a simple yet effective method, named Stochastic WeightAveraging Densely (SWAD),== %%POSTFIX%%to find flat minima. SWAD finds*
>%%LINK%%[[#^gm8wliisho|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gm8wliisho


>%%
>```annotation-json
>{"created":"2023-09-27T04:12:33.192Z","updated":"2023-09-27T04:12:33.192Z","document":{"title":"NeurIPS-2021-swad-domain-generalization-by-seeking-flat-minima-Paper.pdf","link":[{"href":"urn:x-pdf:7aedd41fa0e0b1afddabbfe8c70653a2"},{"href":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf"}],"documentFingerprint":"7aedd41fa0e0b1afddabbfe8c70653a2"},"uri":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf","target":[{"source":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf","selector":[{"type":"TextPositionSelector","start":2594,"end":2707},{"type":"TextQuoteSelector","exact":"Domain generalization (DG) aims to address domain shift simulated by training and evaluatingon different domains.","prefix":"ailed by traditional approaches.","suffix":" DG tasks assume that both task "}]}]}
>```
>%%
>*%%PREFIX%%ailed by traditional approaches.%%HIGHLIGHT%% ==Domain generalization (DG) aims to address domain shift simulated by training and evaluatingon different domains.== %%POSTFIX%%DG tasks assume that both task*
>%%LINK%%[[#^40mlxbxlh2f|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^40mlxbxlh2f


>%%
>```annotation-json
>{"created":"2023-10-09T13:17:38.623Z","updated":"2023-10-09T13:17:38.623Z","document":{"title":"NeurIPS-2021-swad-domain-generalization-by-seeking-flat-minima-Paper.pdf","link":[{"href":"urn:x-pdf:7aedd41fa0e0b1afddabbfe8c70653a2"},{"href":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf"}],"documentFingerprint":"7aedd41fa0e0b1afddabbfe8c70653a2"},"uri":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf","target":[{"source":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf","selector":[{"type":"TextPositionSelector","start":12565,"end":12797},{"type":"TextQuoteSelector","exact":"t implies that if we find the optimal solution of the RRM (i.e., ˆθγ), thenthe generalization gap in the test domain (i.e., ET(ˆθγ) −minθ′ET (θ′)) is upper bounded by thegap between the RRM and ERM (i.e., ˆEγD(ˆθγ) −minθ′′ˆED(θ′′)).","prefix":"ing).Proof is in Appendix C.3. I","suffix":" Other terms in Theorem 2 are th"}]}]}
>```
>%%
>*%%PREFIX%%ing).Proof is in Appendix C.3. I%%HIGHLIGHT%% ==t implies that if we find the optimal solution of the RRM (i.e., ˆθγ), thenthe generalization gap in the test domain (i.e., ET(ˆθγ) −minθ′ET (θ′)) is upper bounded by thegap between the RRM and ERM (i.e., ˆEγD(ˆθγ) −minθ′′ˆED(θ′′)).== %%POSTFIX%%Other terms in Theorem 2 are th*
>%%LINK%%[[#^gwqk9beb67s|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gwqk9beb67s


>%%
>```annotation-json
>{"created":"2023-10-09T13:18:53.339Z","updated":"2023-10-09T13:18:53.339Z","document":{"title":"NeurIPS-2021-swad-domain-generalization-by-seeking-flat-minima-Paper.pdf","link":[{"href":"urn:x-pdf:7aedd41fa0e0b1afddabbfe8c70653a2"},{"href":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf"}],"documentFingerprint":"7aedd41fa0e0b1afddabbfe8c70653a2"},"uri":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf","target":[{"source":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf","selector":[{"type":"TextPositionSelector","start":12958,"end":13217},{"type":"TextQuoteSelector","exact":"if we choose a proper γ, the optimal solution of the RRM will finda point near a flat optimum of ERM as shown in Figure 1. Hence, Theorem 2 and the intuition fromFigure 1 imply that seeking a flat minimum of ERM will lead to a better domain generalization gap","prefix":"by sample means. We remark that ","suffix":".3 SWAD: Domain Generalization b"}]}]}
>```
>%%
>*%%PREFIX%%by sample means. We remark that%%HIGHLIGHT%% ==if we choose a proper γ, the optimal solution of the RRM will finda point near a flat optimum of ERM as shown in Figure 1. Hence, Theorem 2 and the intuition fromFigure 1 imply that seeking a flat minimum of ERM will lead to a better domain generalization gap== %%POSTFIX%%.3 SWAD: Domain Generalization b*
>%%LINK%%[[#^xzkazoai9z9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xzkazoai9z9


>%%
>```annotation-json
>{"created":"2023-10-09T13:43:02.183Z","updated":"2023-10-09T13:43:02.183Z","document":{"title":"NeurIPS-2021-swad-domain-generalization-by-seeking-flat-minima-Paper.pdf","link":[{"href":"urn:x-pdf:7aedd41fa0e0b1afddabbfe8c70653a2"},{"href":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf"}],"documentFingerprint":"7aedd41fa0e0b1afddabbfe8c70653a2"},"uri":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf","target":[{"source":"https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf","selector":[{"type":"TextPositionSelector","start":8927,"end":9030},{"type":"TextQuoteSelector","exact":"robust empirical loss function defined bythe worst-case loss within neighborhoods in the parameterspace","prefix":" find flat minima.We consider a ","suffix":" as ˆEγD(θ) := max‖∆‖≤γ ˆED(θ + "}]}]}
>```
>%%
>*%%PREFIX%%find flat minima.We consider a%%HIGHLIGHT%% ==robust empirical loss function defined bythe worst-case loss within neighborhoods in the parameterspace== %%POSTFIX%%as ˆEγD(θ) := max‖∆‖≤γ ˆED(θ +*
>%%LINK%%[[#^qdt1zyv2g6b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qdt1zyv2g6b
